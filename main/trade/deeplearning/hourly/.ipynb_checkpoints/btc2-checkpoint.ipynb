{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from WindowGenerator import WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>ema12</th>\n",
       "      <th>ema24</th>\n",
       "      <th>ema48</th>\n",
       "      <th>vwma</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-11 00:00:00</th>\n",
       "      <td>246.30</td>\n",
       "      <td>245.733371</td>\n",
       "      <td>245.733371</td>\n",
       "      <td>245.733371</td>\n",
       "      <td>245.632542</td>\n",
       "      <td>5.506550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11 01:00:00</th>\n",
       "      <td>246.30</td>\n",
       "      <td>245.836394</td>\n",
       "      <td>245.836394</td>\n",
       "      <td>245.836394</td>\n",
       "      <td>245.725661</td>\n",
       "      <td>5.506550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11 02:00:00</th>\n",
       "      <td>246.30</td>\n",
       "      <td>245.920686</td>\n",
       "      <td>245.920686</td>\n",
       "      <td>245.920686</td>\n",
       "      <td>245.818708</td>\n",
       "      <td>5.506550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11 03:00:00</th>\n",
       "      <td>246.30</td>\n",
       "      <td>245.989652</td>\n",
       "      <td>245.989652</td>\n",
       "      <td>245.989652</td>\n",
       "      <td>245.911686</td>\n",
       "      <td>5.506550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11 04:00:00</th>\n",
       "      <td>246.30</td>\n",
       "      <td>246.046079</td>\n",
       "      <td>246.046079</td>\n",
       "      <td>246.046079</td>\n",
       "      <td>246.004593</td>\n",
       "      <td>5.506550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23 19:00:00</th>\n",
       "      <td>9186.01</td>\n",
       "      <td>9179.465780</td>\n",
       "      <td>9179.465780</td>\n",
       "      <td>9179.465780</td>\n",
       "      <td>9169.374777</td>\n",
       "      <td>9.125437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23 20:00:00</th>\n",
       "      <td>9238.75</td>\n",
       "      <td>9190.244729</td>\n",
       "      <td>9190.244729</td>\n",
       "      <td>9190.244729</td>\n",
       "      <td>9179.574617</td>\n",
       "      <td>9.131162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23 21:00:00</th>\n",
       "      <td>9235.01</td>\n",
       "      <td>9198.383869</td>\n",
       "      <td>9198.383869</td>\n",
       "      <td>9198.383869</td>\n",
       "      <td>9184.846033</td>\n",
       "      <td>9.130757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23 22:00:00</th>\n",
       "      <td>9228.26</td>\n",
       "      <td>9203.815893</td>\n",
       "      <td>9203.815893</td>\n",
       "      <td>9203.815893</td>\n",
       "      <td>9195.036730</td>\n",
       "      <td>9.130026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23 23:00:00</th>\n",
       "      <td>9175.00</td>\n",
       "      <td>9198.576640</td>\n",
       "      <td>9198.576640</td>\n",
       "      <td>9198.576640</td>\n",
       "      <td>9196.569181</td>\n",
       "      <td>9.124238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40488 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       close        ema12        ema24        ema48  \\\n",
       "Date                                                                  \n",
       "2015-10-11 00:00:00   246.30   245.733371   245.733371   245.733371   \n",
       "2015-10-11 01:00:00   246.30   245.836394   245.836394   245.836394   \n",
       "2015-10-11 02:00:00   246.30   245.920686   245.920686   245.920686   \n",
       "2015-10-11 03:00:00   246.30   245.989652   245.989652   245.989652   \n",
       "2015-10-11 04:00:00   246.30   246.046079   246.046079   246.046079   \n",
       "...                      ...          ...          ...          ...   \n",
       "2020-05-23 19:00:00  9186.01  9179.465780  9179.465780  9179.465780   \n",
       "2020-05-23 20:00:00  9238.75  9190.244729  9190.244729  9190.244729   \n",
       "2020-05-23 21:00:00  9235.01  9198.383869  9198.383869  9198.383869   \n",
       "2020-05-23 22:00:00  9228.26  9203.815893  9203.815893  9203.815893   \n",
       "2020-05-23 23:00:00  9175.00  9198.576640  9198.576640  9198.576640   \n",
       "\n",
       "                            vwma       log  \n",
       "Date                                        \n",
       "2015-10-11 00:00:00   245.632542  5.506550  \n",
       "2015-10-11 01:00:00   245.725661  5.506550  \n",
       "2015-10-11 02:00:00   245.818708  5.506550  \n",
       "2015-10-11 03:00:00   245.911686  5.506550  \n",
       "2015-10-11 04:00:00   246.004593  5.506550  \n",
       "...                          ...       ...  \n",
       "2020-05-23 19:00:00  9169.374777  9.125437  \n",
       "2020-05-23 20:00:00  9179.574617  9.131162  \n",
       "2020-05-23 21:00:00  9184.846033  9.130757  \n",
       "2020-05-23 22:00:00  9195.036730  9.130026  \n",
       "2020-05-23 23:00:00  9196.569181  9.124238  \n",
       "\n",
       "[40488 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('BTC_USD_2015-10-08_2020-05-27_Gemini_Hourly.csv')\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "df.loc[:, 'ema12'] = df.ta.ema(12)\n",
    "df.loc[:, 'ema24'] = df.ta.ema(24)\n",
    "df.loc[:, 'ema48'] = df.ta.ema(48)\n",
    "df.loc[:, 'vwma'] = df.ta.vwma()\n",
    "df.loc[:, 'log'] = np.log(df.close)\n",
    "\n",
    "df.drop(['currency', 'open', 'high', 'low', 'volume'], axis=1, inplace=True)\n",
    "df = df[48:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original df: 40488\n",
      "Length of train df: 28341\n",
      "Length of val df: 8098\n",
      "Length of test df: 4049\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "n = len(df)\n",
    "print(f'Length of original df: {n}')\n",
    "\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "print(f'Length of train df: {len(train_df)}')\n",
    "print(f'Length of val df: {len(val_df)}')\n",
    "print(f'Length of test df: {len(test_df)}')\n",
    "\n",
    "INPUT_WIDTH = 20\n",
    "LABEL_SHIFT = 4\n",
    "LABEL_WIDTH = 4\n",
    "MAX_EPOCHS = 100\n",
    "STD = train_df.close.std()\n",
    "MEAN = train_df.close.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harvir/Code/venvs/tensorflow_venv/lib/python3.8/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/harvir/Code/venvs/tensorflow_venv/lib/python3.8/site-packages/pandas/core/indexing.py:1048: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/home/harvir/Code/venvs/tensorflow_venv/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_normal</th>\n",
       "      <th>ema12_normal</th>\n",
       "      <th>ema24_normal</th>\n",
       "      <th>ema48_normal</th>\n",
       "      <th>vwma_normal</th>\n",
       "      <th>log_normal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-11 00:00:00</th>\n",
       "      <td>-0.906402</td>\n",
       "      <td>-0.906648</td>\n",
       "      <td>-0.906648</td>\n",
       "      <td>-0.906648</td>\n",
       "      <td>-0.906504</td>\n",
       "      <td>-1.670365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11 01:00:00</th>\n",
       "      <td>-0.906402</td>\n",
       "      <td>-0.906622</td>\n",
       "      <td>-0.906622</td>\n",
       "      <td>-0.906622</td>\n",
       "      <td>-0.906480</td>\n",
       "      <td>-1.670365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11 02:00:00</th>\n",
       "      <td>-0.906402</td>\n",
       "      <td>-0.906600</td>\n",
       "      <td>-0.906600</td>\n",
       "      <td>-0.906600</td>\n",
       "      <td>-0.906456</td>\n",
       "      <td>-1.670365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11 03:00:00</th>\n",
       "      <td>-0.906402</td>\n",
       "      <td>-0.906582</td>\n",
       "      <td>-0.906582</td>\n",
       "      <td>-0.906582</td>\n",
       "      <td>-0.906432</td>\n",
       "      <td>-1.670365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11 04:00:00</th>\n",
       "      <td>-0.906402</td>\n",
       "      <td>-0.906568</td>\n",
       "      <td>-0.906568</td>\n",
       "      <td>-0.906568</td>\n",
       "      <td>-0.906408</td>\n",
       "      <td>-1.670365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     close_normal  ema12_normal  ema24_normal  ema48_normal  \\\n",
       "Date                                                                          \n",
       "2015-10-11 00:00:00     -0.906402     -0.906648     -0.906648     -0.906648   \n",
       "2015-10-11 01:00:00     -0.906402     -0.906622     -0.906622     -0.906622   \n",
       "2015-10-11 02:00:00     -0.906402     -0.906600     -0.906600     -0.906600   \n",
       "2015-10-11 03:00:00     -0.906402     -0.906582     -0.906582     -0.906582   \n",
       "2015-10-11 04:00:00     -0.906402     -0.906568     -0.906568     -0.906568   \n",
       "\n",
       "                     vwma_normal  log_normal  \n",
       "Date                                          \n",
       "2015-10-11 00:00:00    -0.906504   -1.670365  \n",
       "2015-10-11 01:00:00    -0.906480   -1.670365  \n",
       "2015-10-11 02:00:00    -0.906456   -1.670365  \n",
       "2015-10-11 03:00:00    -0.906432   -1.670365  \n",
       "2015-10-11 04:00:00    -0.906408   -1.670365  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inf_to_zero(x):\n",
    "    return 0 if x == -np.inf else x\n",
    "\n",
    "# Standardise data\n",
    "def standardise(df, column, mean, std):\n",
    "    vals = df[col].values\n",
    "    df.loc[:, column+'_normal'] = pd.Series((vals - mean) / std, index=df.index, dtype=np.float64)\n",
    "    # df.loc[:, column+'_normal'] = pd.Series(np.vectorize(inf_to_zero)(np.log(vals)).astype(np.float64), index=df.index)\n",
    "\n",
    "cols = [x for x in train_df.columns]\n",
    "\n",
    "norms = {}\n",
    "\n",
    "for col in cols:\n",
    "    vals = train_df[col].values\n",
    "    std = vals.std()\n",
    "    mean = vals.mean()\n",
    "    norms[col+'_std'] = std\n",
    "    norms[col+'_mean'] = mean\n",
    "    for df in [train_df, test_df, val_df]:\n",
    "        standardise(df, col, mean, std)\n",
    "\n",
    "train_df.drop(cols, axis=1, inplace=True)\n",
    "val_df.drop(cols, axis=1, inplace=True)\n",
    "test_df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 24\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
       "Label indices: [20 21 22 23]\n",
       "Label column name(s): ['close_normal']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = WindowGenerator(input_width=INPUT_WIDTH, label_width=LABEL_WIDTH, shift=LABEL_SHIFT, \n",
    "                         train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "                         label_columns=['close_normal'])\n",
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_SIZE = INPUT_WIDTH*len(df.columns)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss') < 6 and logs.get('val_loss') < 17):\n",
    "            print(\"\\nReached less than 6% loss so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "early_stop = myCallback()\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1)),\n",
    "    tf.keras.layers.LSTM(LSTM_SIZE, input_shape=[1, LSTM_SIZE]),\n",
    "#     tf.keras.layers.Dense(int(LSTM_SIZE/2), activation=\"relu\", input_shape=[1, int(LSTM_SIZE/2)]),\n",
    "#     tf.keras.layers.Dense(int(LSTM_SIZE/4), activation=\"relu\", input_shape=[1, int(LSTM_SIZE/4)]),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.losses.MeanAbsolutePercentageError(),\n",
    "            optimizer=tf.optimizers.Adam())\n",
    "\n",
    "# model.compile(loss=tf.losses.Huber(),\n",
    "#               optimizer=tf.optimizers.Adam(),\n",
    "#              metrics=['mape'])\n",
    "\n",
    "history = model.fit(window.train, epochs=MAX_EPOCHS, batch_size=96,\n",
    "                    validation_data=window.val, verbose=1) # , callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0\n",
    "min_loss = min(history.history['loss'])\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "print(f'Minimum training loss: {min_loss}')\n",
    "print(f'Minimum validation loss: {min_val_loss}')\n",
    "\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['loss'][SPLIT:], label='loss')\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['val_loss'][SPLIT:], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0\n",
    "min_loss = min(history.history['loss'])\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "min_mape = min(history.history['mape'])\n",
    "min_val_mape = min(history.history['val_mape'])\n",
    "\n",
    "print(f'Minimum training loss: {min_loss}')\n",
    "print(f'Minimum validation loss: {min_val_loss}')\n",
    "\n",
    "print(f'Minimum training mape: {min_mape}')\n",
    "print(f'Minimum validation mape: {min_val_mape}')\n",
    "\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['loss'][SPLIT:], label='loss')\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['val_loss'][SPLIT:], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['mape'][SPLIT:], label='mape')\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['val_mape'][SPLIT:], label='val_mape')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_history = model.fit(window.val, epochs=int(MAX_EPOCHS/3), batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0\n",
    "min_loss = min(validation_history.history['loss'])\n",
    "\n",
    "print(f'Minimum training loss: {min_loss}')\n",
    "\n",
    "plt.plot([x for x in range(1, int(MAX_EPOCHS/3)+1)][SPLIT:], validation_history.history['loss'][SPLIT:], label='loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 36ms/step - loss: 1.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8699779510498047"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(window.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for i in range(5, 20):\n",
    "    new_df = test_df.iloc[(INPUT_WIDTH*i):(INPUT_WIDTH*(i+1))+LABEL_SHIFT]\n",
    "    input = tf.stack([row.values for _, row in new_df.iloc[:INPUT_WIDTH].iterrows()])\n",
    "    input = tf.expand_dims(input, axis=0)\n",
    "\n",
    "#     actual = np.exp(model.predict(input)[0][0])\n",
    "#     expected = np.exp(new_df.iloc[-1]['close_normal'])\n",
    "#     new_df.loc[:, 'close'] = pd.Series(np.exp(new_df['close_normal'].values), index=new_df.index)\n",
    "\n",
    "    actual = (model.predict(input)[0][0] * norms['close_std']) + norms['close_mean']\n",
    "    expected = (new_df.iloc[-1]['close_normal'] * norms['close_std']) + norms['close_mean']\n",
    "    new_df.loc[:, 'close'] = pd.Series((new_df['close_normal'].values*norms['close_std'])+norms['close_mean'], index=new_df.index)\n",
    "\n",
    "    if LABEL_SHIFT > 1:\n",
    "        plt.plot([x for x in range(-INPUT_WIDTH, 1)], new_df['close'][:INPUT_WIDTH+1])\n",
    "        plt.plot([x for x in range(0, LABEL_SHIFT)], new_df['close'][INPUT_WIDTH:], linestyle='dotted')\n",
    "        plt.plot([0, LABEL_SHIFT-1], \n",
    "                     [new_df['close'][INPUT_WIDTH], actual],\n",
    "                     marker='o', linestyle='dotted')\n",
    "    else:\n",
    "        plt.plot(new_df.index, new_df['close'])\n",
    "        plt.plot(new_df.index[-1], actual, marker='o')\n",
    "    print(f'Diff is {actual-expected}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS = 0\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(40, 60))\n",
    "\n",
    "for i in range(3, 13):\n",
    "    new_df = test_df.iloc[(INPUT_WIDTH*i):(INPUT_WIDTH*(i+1))+LABEL_SHIFT]\n",
    "    input = tf.stack([row.values for _, row in new_df.iterrows()])[:-1]\n",
    "    input = tf.expand_dims(input, axis=0)\n",
    "    \n",
    "    actual = ((model.predict(input)*STD)+MEAN)[0][0]\n",
    "    expected = (tf.stack([row.values for _, row in new_df.iterrows()])[-1].numpy()[0]*STD)+MEAN\n",
    "    \n",
    "    new_df.loc[:, 'close'] = pd.Series((new_df['close_normal'].values*STD)+MEAN, index=new_df.index)\n",
    "    \n",
    "    \n",
    "    if i%2 == 0:\n",
    "        j = 1\n",
    "    else:\n",
    "        j = 0\n",
    "    \n",
    "    i = i-3\n",
    "    map = {0: 0, 1: 0, 2:1, 3:1, 4:2, 5:2, 6:3, 7:3, 8:4, 9:4}\n",
    "    i = map[i]\n",
    "    if LABEL_SHIFT > 1:\n",
    "        # axes[i].plot(new_df.index[:INPUT_WIDTH+1], new_df['close'][:INPUT_WIDTH+1])\n",
    "        axes[i][j].plot([x for x in range(-INPUT_WIDTH, 1)], new_df['close'][:INPUT_WIDTH+1])\n",
    "        # axes[i].plot(new_df.index[INPUT_WIDTH:], new_df['close'][INPUT_WIDTH:], linestyle='dotted')\n",
    "        axes[i][j].plot([x for x in range(0, LABEL_SHIFT)], new_df['close'][INPUT_WIDTH:], linestyle='dotted')\n",
    "#         axes[i].plot([new_df.index[INPUT_WIDTH], new_df.index[-1]], \n",
    "#                      [new_df['close'][INPUT_WIDTH], actual],\n",
    "#                      marker='o', linestyle='dotted')\n",
    "        axes[i][j].plot([0, LABEL_SHIFT-1], \n",
    "                     [new_df['close'][INPUT_WIDTH], actual],\n",
    "                     marker='o', linestyle='dotted')\n",
    "        axes[i][j].set_title(f'{new_df.index[0]} to {new_df.index[-1]}')\n",
    "        axes[i][j].set_xlabel('Tn (hour)')\n",
    "        axes[i][j].set_ylabel('Price (USD)')\n",
    "    else:\n",
    "        axes[i].plot(new_df.index, new_df['close'])\n",
    "        axes[i].plot(new_df.index[-1], actual, marker='o')\n",
    "    print(f'Diff is {actual-expected}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BTC_USD_122448EMAs_VWAP_LOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
