{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from WindowGenerator import WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>ema12</th>\n",
       "      <th>ema24</th>\n",
       "      <th>ema48</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 13:00:00</th>\n",
       "      <td>107.77</td>\n",
       "      <td>107.163098</td>\n",
       "      <td>107.163098</td>\n",
       "      <td>107.163098</td>\n",
       "      <td>4.679999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 14:00:00</th>\n",
       "      <td>107.97</td>\n",
       "      <td>107.309808</td>\n",
       "      <td>107.309808</td>\n",
       "      <td>107.309808</td>\n",
       "      <td>4.681853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:00:00</th>\n",
       "      <td>107.10</td>\n",
       "      <td>107.271661</td>\n",
       "      <td>107.271661</td>\n",
       "      <td>107.271661</td>\n",
       "      <td>4.673763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 16:00:00</th>\n",
       "      <td>107.68</td>\n",
       "      <td>107.345904</td>\n",
       "      <td>107.345904</td>\n",
       "      <td>107.345904</td>\n",
       "      <td>4.679164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 17:00:00</th>\n",
       "      <td>107.89</td>\n",
       "      <td>107.444831</td>\n",
       "      <td>107.444831</td>\n",
       "      <td>107.444831</td>\n",
       "      <td>4.681112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 20:00:00</th>\n",
       "      <td>545.80</td>\n",
       "      <td>542.947438</td>\n",
       "      <td>542.947438</td>\n",
       "      <td>542.947438</td>\n",
       "      <td>6.302253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 21:00:00</th>\n",
       "      <td>541.76</td>\n",
       "      <td>542.731540</td>\n",
       "      <td>542.731540</td>\n",
       "      <td>542.731540</td>\n",
       "      <td>6.294823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 22:00:00</th>\n",
       "      <td>543.00</td>\n",
       "      <td>542.780351</td>\n",
       "      <td>542.780351</td>\n",
       "      <td>542.780351</td>\n",
       "      <td>6.297109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 23:00:00</th>\n",
       "      <td>539.71</td>\n",
       "      <td>542.222105</td>\n",
       "      <td>542.222105</td>\n",
       "      <td>542.222105</td>\n",
       "      <td>6.291032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 00:00:00</th>\n",
       "      <td>538.57</td>\n",
       "      <td>541.558086</td>\n",
       "      <td>541.558086</td>\n",
       "      <td>541.558086</td>\n",
       "      <td>6.288917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17529 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      close       ema12       ema24       ema48       log\n",
       "time                                                                     \n",
       "2019-01-01 13:00:00  107.77  107.163098  107.163098  107.163098  4.679999\n",
       "2019-01-01 14:00:00  107.97  107.309808  107.309808  107.309808  4.681853\n",
       "2019-01-01 15:00:00  107.10  107.271661  107.271661  107.271661  4.673763\n",
       "2019-01-01 16:00:00  107.68  107.345904  107.345904  107.345904  4.679164\n",
       "2019-01-01 17:00:00  107.89  107.444831  107.444831  107.444831  4.681112\n",
       "...                     ...         ...         ...         ...       ...\n",
       "2020-12-31 20:00:00  545.80  542.947438  542.947438  542.947438  6.302253\n",
       "2020-12-31 21:00:00  541.76  542.731540  542.731540  542.731540  6.294823\n",
       "2020-12-31 22:00:00  543.00  542.780351  542.780351  542.780351  6.297109\n",
       "2020-12-31 23:00:00  539.71  542.222105  542.222105  542.222105  6.291032\n",
       "2021-01-01 00:00:00  538.57  541.558086  541.558086  541.558086  6.288917\n",
       "\n",
       "[17529 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('COINBASE-ETHGBP-20190101-20210101.csv')\n",
    "df.set_index('time', inplace=True)\n",
    "\n",
    "df.loc[:, 'ema12'] = df.ta.ema(12)\n",
    "df.loc[:, 'ema24'] = df.ta.ema(24)\n",
    "df.loc[:, 'ema48'] = df.ta.ema(48)\n",
    "# df.loc[:, 'rsi'] = df.ta.rsi()\n",
    "# df.loc[:, 'vwma'] = df.ta.vwma()\n",
    "df.loc[:, 'log'] = np.log(df.close)\n",
    "\n",
    "# df.loc[:, 'return'] = ((df.close - df.close.shift(1))/df.close)*100\n",
    "# df.loc[:, 'direction'] = df['return'] / abs(df['return']) * 0.1\n",
    "\n",
    "df.drop(['open', 'high', 'low', 'volume'], axis=1, inplace=True)\n",
    "df = df[12:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original df: 17529\n",
      "Length of train df: 12270\n",
      "Length of val df: 3506\n",
      "Length of test df: 1753\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "n = len(df)\n",
    "print(f'Length of original df: {n}')\n",
    "\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "print(f'Length of train df: {len(train_df)}')\n",
    "print(f'Length of val df: {len(val_df)}')\n",
    "print(f'Length of test df: {len(test_df)}')\n",
    "\n",
    "INPUT_WIDTH = 12\n",
    "LABEL_SHIFT = 1\n",
    "LABEL_WIDTH = 1\n",
    "MAX_EPOCHS = 50\n",
    "STD = train_df.close.std()\n",
    "MEAN = train_df.close.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harvir/Code/venvs/backtesting_venv/lib/python3.8/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/harvir/Code/venvs/backtesting_venv/lib/python3.8/site-packages/pandas/core/indexing.py:1048: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/home/harvir/Code/venvs/backtesting_venv/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/harvir/Code/venvs/backtesting_venv/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_normal</th>\n",
       "      <th>ema12_normal</th>\n",
       "      <th>ema24_normal</th>\n",
       "      <th>ema48_normal</th>\n",
       "      <th>log_normal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 13:00:00</th>\n",
       "      <td>-0.919601</td>\n",
       "      <td>-0.936040</td>\n",
       "      <td>-0.936040</td>\n",
       "      <td>-0.936040</td>\n",
       "      <td>-0.947096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 14:00:00</th>\n",
       "      <td>-0.914471</td>\n",
       "      <td>-0.932271</td>\n",
       "      <td>-0.932271</td>\n",
       "      <td>-0.932271</td>\n",
       "      <td>-0.940117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:00:00</th>\n",
       "      <td>-0.936786</td>\n",
       "      <td>-0.933251</td>\n",
       "      <td>-0.933251</td>\n",
       "      <td>-0.933251</td>\n",
       "      <td>-0.970571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 16:00:00</th>\n",
       "      <td>-0.921909</td>\n",
       "      <td>-0.931344</td>\n",
       "      <td>-0.931344</td>\n",
       "      <td>-0.931344</td>\n",
       "      <td>-0.950241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 17:00:00</th>\n",
       "      <td>-0.916523</td>\n",
       "      <td>-0.928803</td>\n",
       "      <td>-0.928803</td>\n",
       "      <td>-0.928803</td>\n",
       "      <td>-0.942907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     close_normal  ema12_normal  ema24_normal  ema48_normal  \\\n",
       "time                                                                          \n",
       "2019-01-01 13:00:00     -0.919601     -0.936040     -0.936040     -0.936040   \n",
       "2019-01-01 14:00:00     -0.914471     -0.932271     -0.932271     -0.932271   \n",
       "2019-01-01 15:00:00     -0.936786     -0.933251     -0.933251     -0.933251   \n",
       "2019-01-01 16:00:00     -0.921909     -0.931344     -0.931344     -0.931344   \n",
       "2019-01-01 17:00:00     -0.916523     -0.928803     -0.928803     -0.928803   \n",
       "\n",
       "                     log_normal  \n",
       "time                             \n",
       "2019-01-01 13:00:00   -0.947096  \n",
       "2019-01-01 14:00:00   -0.940117  \n",
       "2019-01-01 15:00:00   -0.970571  \n",
       "2019-01-01 16:00:00   -0.950241  \n",
       "2019-01-01 17:00:00   -0.942907  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inf_to_zero(x):\n",
    "    return 0 if x == -np.inf else x\n",
    "\n",
    "# Standardise data\n",
    "def standardise(df, column, mean, std):\n",
    "    vals = df[col].values\n",
    "    df.loc[:, column+'_normal'] = pd.Series((vals - mean) / std, index=df.index, dtype=np.float32)\n",
    "    \n",
    "cols = [x for x in train_df.columns if 'direction' not in x]\n",
    "\n",
    "norms = {}\n",
    "\n",
    "for col in cols:\n",
    "    vals = train_df[col].values\n",
    "    std = vals.std()\n",
    "    mean = vals.mean()\n",
    "    norms[col+'_std'] = std\n",
    "    norms[col+'_mean'] = mean\n",
    "    for df in [train_df, test_df, val_df]:\n",
    "        standardise(df, col, mean, std)\n",
    "\n",
    "train_df.drop(cols, axis=1, inplace=True)\n",
    "val_df.drop(cols, axis=1, inplace=True)\n",
    "test_df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total window size: 13\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
       "Label indices: [12]\n",
       "Label column name(s): ['close_normal']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = WindowGenerator(input_width=INPUT_WIDTH, label_width=LABEL_WIDTH, shift=LABEL_SHIFT, \n",
    "                         train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "                         label_columns=['close_normal'])\n",
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.0680 - mape: 41.0206 - val_loss: 0.3421 - val_mape: 10.4011\n",
      "Epoch 2/50\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.0031 - mape: 25.9543 - val_loss: 0.1701 - val_mape: 6.9104\n",
      "Epoch 3/50\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.0029 - mape: 27.1683 - val_loss: 0.0844 - val_mape: 4.4846\n",
      "Epoch 4/50\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.0028 - mape: 25.8994 - val_loss: 0.0490 - val_mape: 3.5605\n",
      "Epoch 5/50\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.0026 - mape: 23.9311 - val_loss: 0.0244 - val_mape: 2.7335\n",
      "Epoch 6/50\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.0026 - mape: 25.5930 - val_loss: 0.0237 - val_mape: 3.2754\n",
      "Epoch 7/50\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.0025 - mape: 23.9171 - val_loss: 0.0133 - val_mape: 2.5008\n",
      "Epoch 8/50\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.0024 - mape: 24.2697 - val_loss: 0.0136 - val_mape: 2.3965\n",
      "Epoch 9/50\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.0024 - mape: 23.7251 - val_loss: 0.0112 - val_mape: 2.3027\n",
      "Epoch 10/50\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.0023 - mape: 24.8123 - val_loss: 0.0161 - val_mape: 2.7213\n",
      "Epoch 11/50\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.0023 - mape: 24.5834 - val_loss: 0.0159 - val_mape: 2.4139\n",
      "Epoch 12/50\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.0023 - mape: 24.7967 - val_loss: 0.0162 - val_mape: 2.4775\n",
      "Epoch 13/50\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.0022 - mape: 24.5917 - val_loss: 0.0283 - val_mape: 2.8704\n",
      "Epoch 14/50\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.0022 - mape: 22.5202 - val_loss: 0.0443 - val_mape: 3.5621\n",
      "Epoch 15/50\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.0021 - mape: 24.3058 - val_loss: 0.0340 - val_mape: 2.9041\n",
      "Epoch 16/50\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.0020 - mape: 24.4701 - val_loss: 0.0752 - val_mape: 4.9057\n",
      "Epoch 17/50\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.0020 - mape: 23.7601 - val_loss: 0.0995 - val_mape: 4.9471\n",
      "Epoch 18/50\n",
      " 69/128 [===============>..............] - ETA: 2s - loss: 0.0021 - mape: 28.5567"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9e53a8785b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             optimizer=tf.optimizers.Adam(), metrics=['mape'])\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m history = model.fit(window.train, epochs=MAX_EPOCHS, batch_size=96,\n\u001b[0m\u001b[1;32m     25\u001b[0m                     validation_data=window.val, verbose=1) # , callbacks=[early_stop])\n",
      "\u001b[0;32m~/Code/venvs/backtesting_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/venvs/backtesting_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/venvs/backtesting_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/venvs/backtesting_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/venvs/backtesting_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/venvs/backtesting_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/Code/venvs/backtesting_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Code/venvs/backtesting_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/venvs/backtesting_venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTM_SIZE = INPUT_WIDTH*len(df.columns)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss') < 6 and logs.get('val_loss') < 17):\n",
    "            print(\"\\nReached less than 6% loss so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "early_stop = myCallback()\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1)),\n",
    "    tf.keras.layers.LSTM(LSTM_SIZE, input_shape=[1, LSTM_SIZE]),\n",
    "#     tf.keras.layers.Dense(int(LSTM_SIZE/2), activation=\"relu\", input_shape=[1, int(LSTM_SIZE/2)]),\n",
    "#     tf.keras.layers.Dense(int(LSTM_SIZE/4), activation=\"relu\", input_shape=[1, int(LSTM_SIZE/4)]),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "            optimizer=tf.optimizers.Adam(), metrics=['mape'])\n",
    "\n",
    "history = model.fit(window.train, epochs=MAX_EPOCHS, batch_size=96,\n",
    "                    validation_data=window.val, verbose=1) # , callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0\n",
    "min_loss = min(history.history['loss'])\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "print(f'Minimum training loss: {min_loss}')\n",
    "print(f'Minimum validation loss: {min_val_loss}')\n",
    "\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['loss'][SPLIT:], label='loss')\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['val_loss'][SPLIT:], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0\n",
    "min_loss = min(history.history['loss'])\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "min_mape = min(history.history['mape'])\n",
    "min_val_mape = min(history.history['val_mape'])\n",
    "\n",
    "print(f'Minimum training loss: {min_loss}')\n",
    "print(f'Minimum validation loss: {min_val_loss}')\n",
    "\n",
    "print(f'Minimum training mape: {min_mape}')\n",
    "print(f'Minimum validation mape: {min_val_mape}')\n",
    "\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['loss'][SPLIT:], label='loss')\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['val_loss'][SPLIT:], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['mape'][SPLIT:], label='mape')\n",
    "plt.plot([x for x in range(1, MAX_EPOCHS+1)][SPLIT:], history.history['val_mape'][SPLIT:], label='val_mape')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_history = model.fit(window.val, epochs=int(MAX_EPOCHS/3), batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0\n",
    "min_loss = min(validation_history.history['loss'])\n",
    "\n",
    "print(f'Minimum training loss: {min_loss}')\n",
    "\n",
    "plt.plot([x for x in range(1, int(MAX_EPOCHS/3)+1)][SPLIT:], validation_history.history['loss'][SPLIT:], label='loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(window.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('BTC_USD_122448EMAs_VWAP_LOG_4HR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for i in range(20, 40):\n",
    "    new_df = test_df.iloc[(INPUT_WIDTH*i):(INPUT_WIDTH*(i+1))+LABEL_SHIFT]\n",
    "    input = tf.stack([row.values for _, row in new_df.iloc[:INPUT_WIDTH].iterrows()])\n",
    "    input = tf.expand_dims(input, axis=0)\n",
    "\n",
    "    actual = (model.predict(input)[0][0] * norms['close_std']) + norms['close_mean']\n",
    "    \n",
    "    expected = (new_df.iloc[-1]['close_normal'] * norms['close_std']) + norms['close_mean']\n",
    "    new_df.loc[:, 'close'] = pd.Series((new_df['close_normal'].values*norms['close_std'])+norms['close_mean'], index=new_df.index)\n",
    "\n",
    "    if LABEL_SHIFT > 1:\n",
    "        plt.plot([x for x in range(-INPUT_WIDTH, 1)], new_df['close'][:INPUT_WIDTH+1])\n",
    "        plt.plot([x for x in range(0, LABEL_SHIFT)], new_df['close'][INPUT_WIDTH:], linestyle='dotted')\n",
    "        plt.plot([0, LABEL_SHIFT-1], \n",
    "                [new_df['close'][INPUT_WIDTH], actual],\n",
    "                marker='o', linestyle='dotted')\n",
    "    else:\n",
    "        plt.plot(new_df.index, new_df['close'])\n",
    "        plt.plot(new_df.index[-1], actual, marker='o')\n",
    "    print(f'Diff is {actual-expected}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS = 0\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(40, 60))\n",
    "\n",
    "for i in range(3, 13):\n",
    "    new_df = test_df.iloc[(INPUT_WIDTH*i):(INPUT_WIDTH*(i+1))+LABEL_SHIFT]\n",
    "    input = tf.stack([row.values for _, row in new_df.iterrows()])[:-1]\n",
    "    input = tf.expand_dims(input, axis=0)\n",
    "    \n",
    "    actual = ((model.predict(input)*STD)+MEAN)[0][0]\n",
    "    expected = (tf.stack([row.values for _, row in new_df.iterrows()])[-1].numpy()[0]*STD)+MEAN\n",
    "    \n",
    "    new_df.loc[:, 'close'] = pd.Series((new_df['close_normal'].values*STD)+MEAN, index=new_df.index)\n",
    "    \n",
    "    \n",
    "    if i%2 == 0:\n",
    "        j = 1\n",
    "    else:\n",
    "        j = 0\n",
    "    \n",
    "    i = i-3\n",
    "    map = {0: 0, 1: 0, 2:1, 3:1, 4:2, 5:2, 6:3, 7:3, 8:4, 9:4}\n",
    "    i = map[i]\n",
    "    if LABEL_SHIFT > 1:\n",
    "        # axes[i].plot(new_df.index[:INPUT_WIDTH+1], new_df['close'][:INPUT_WIDTH+1])\n",
    "        axes[i][j].plot([x for x in range(-INPUT_WIDTH, 1)], new_df['close'][:INPUT_WIDTH+1])\n",
    "        # axes[i].plot(new_df.index[INPUT_WIDTH:], new_df['close'][INPUT_WIDTH:], linestyle='dotted')\n",
    "        axes[i][j].plot([x for x in range(0, LABEL_SHIFT)], new_df['close'][INPUT_WIDTH:], linestyle='dotted')\n",
    "#         axes[i].plot([new_df.index[INPUT_WIDTH], new_df.index[-1]], \n",
    "#                      [new_df['close'][INPUT_WIDTH], actual],\n",
    "#                      marker='o', linestyle='dotted')\n",
    "        axes[i][j].plot([0, LABEL_SHIFT-1], \n",
    "                     [new_df['close'][INPUT_WIDTH], actual],\n",
    "                     marker='o', linestyle='dotted')\n",
    "        axes[i][j].set_title(f'{new_df.index[0]} to {new_df.index[-1]}')\n",
    "        axes[i][j].set_xlabel('Tn (hour)')\n",
    "        axes[i][j].set_ylabel('Price (USD)')\n",
    "    else:\n",
    "        axes[i].plot(new_df.index, new_df['close'])\n",
    "        axes[i].plot(new_df.index[-1], actual, marker='o')\n",
    "    print(f'Diff is {actual-expected}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BTC_USD_122448EMAs_VWAP_LOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
